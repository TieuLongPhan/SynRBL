{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "from SynRBL.rsmi_utils import load_database\n",
    "import re\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdMolDescriptors import CalcNumRings\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def remove_atom_mapping_from_reaction_smiles(reaction_smiles):\n",
    "    \"\"\"\n",
    "    Remove atom mapping from a reaction SMILES string.\n",
    "    \n",
    "    Parameters:\n",
    "    - reaction_smiles (str): A reaction SMILES string with atom mapping.\n",
    "    \n",
    "    Returns:\n",
    "    - str: A reaction SMILES string without atom mapping.\n",
    "    \"\"\"\n",
    "    # Split the reaction SMILES into its components (reactants, agents, products)\n",
    "    parts = reaction_smiles.split('>>')\n",
    "    \n",
    "    # Remove atom mapping from each part\n",
    "    cleaned_parts = [Chem.CanonSmiles(re.sub(r\":\\d+\", \"\", part)) for part in parts]\n",
    "    \n",
    "    # Concatenate the cleaned parts back into a reaction SMILES string\n",
    "    cleaned_reaction_smiles = '>>'.join(cleaned_parts)\n",
    "    \n",
    "    return cleaned_reaction_smiles\n",
    "\n",
    "\n",
    "\n",
    "def calculate_chemical_properties(dictionary_list):\n",
    "    updated_list = deepcopy(dictionary_list)  # Create a deep copy of the original list\n",
    "    for entry in updated_list:\n",
    "        reactant_smiles = entry['reactants']\n",
    "        product_smiles = entry['products']\n",
    "\n",
    "        # Initialize RDKit molecule objects from SMILES\n",
    "        reactant_mol = Chem.MolFromSmiles(reactant_smiles)\n",
    "        product_mol = Chem.MolFromSmiles(product_smiles)\n",
    "\n",
    "        if reactant_mol is not None and product_mol is not None:\n",
    "            # Calculate carbon difference\n",
    "            num_carbon_reactants = sum([atom.GetAtomicNum() == 6 for atom in reactant_mol.GetAtoms()])\n",
    "            num_carbon_products = sum([atom.GetAtomicNum() == 6 for atom in product_mol.GetAtoms()])\n",
    "            entry['carbon_difference'] = abs(num_carbon_reactants - num_carbon_products)\n",
    "            \n",
    "            # Calculate total number of carbons\n",
    "            entry['total_carbons'] = num_carbon_reactants + num_carbon_products\n",
    "\n",
    "            # Calculate total number of bonds\n",
    "            entry['total_bonds'] = abs(reactant_mol.GetNumBonds() - product_mol.GetNumBonds())\n",
    "\n",
    "            # Calculate total number of rings\n",
    "            entry['total_rings'] = abs(CalcNumRings(reactant_mol) - CalcNumRings(product_mol))\n",
    "        else:\n",
    "            entry['carbon_difference'] = \"Invalid SMILES\"\n",
    "            entry['total_carbons'] = \"Invalid SMILES\"\n",
    "            entry['total_bonds'] = \"Invalid SMILES\"\n",
    "            entry['total_rings'] = \"Invalid SMILES\"\n",
    "\n",
    "\n",
    "\n",
    "        # Process for fragment count calculation\n",
    "        reactant_fragment_count = len(reactant_smiles.split('.'))\n",
    "        product_fragment_count = len(product_smiles.split('.'))\n",
    "        total_fragment_count = reactant_fragment_count + product_fragment_count\n",
    "        entry['fragment_count'] = total_fragment_count\n",
    "\n",
    "    return updated_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def count_boundary_atoms_products_and_calculate_changes(list_of_dicts):\n",
    "    for item in list_of_dicts:\n",
    "        count = 0  # Initialize count for boundary_atoms_products\n",
    "        # Initialize variables for bond and ring changes\n",
    "        bond_change = 0\n",
    "        ring_change = 0\n",
    "        \n",
    "        if 'boundary_atoms_products' in item and item['boundary_atoms_products']:\n",
    "            for i in item['boundary_atoms_products']:\n",
    "                if isinstance(i, dict):\n",
    "                    count += 1\n",
    "                elif isinstance(i, list):\n",
    "                    for j in i:\n",
    "                        if isinstance(j, dict):\n",
    "                            count += 1\n",
    "        \n",
    "        # Split new_reactions into reactant and product SMILES and calculate changes\n",
    "        \n",
    "        reactant_product = item['new_reaction'].split('>>')\n",
    "        if len(reactant_product) == 2:  # Ensure there are both reactant and product\n",
    "            reactant_smiles, product_smiles = reactant_product\n",
    "            reactant_mol = Chem.MolFromSmiles(reactant_smiles)\n",
    "            product_mol = Chem.MolFromSmiles(product_smiles)\n",
    "            \n",
    "            if reactant_mol and product_mol:\n",
    "                # Calculate bond change\n",
    "                bond_change = abs(reactant_mol.GetNumBonds() - product_mol.GetNumBonds())\n",
    "                # Calculate ring change\n",
    "                ring_change = abs(CalcNumRings(reactant_mol) - CalcNumRings(product_mol))\n",
    "        \n",
    "        # Add calculated values to the dictionary\n",
    "        item['num_boundary'] = count\n",
    "        item['bond_change_merge'] = bond_change\n",
    "        item['ring_change_merge'] = ring_change\n",
    "\n",
    "    return list_of_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n",
      "[09:18:07] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from SynRBL.rsmi_utils import load_database\n",
    "from IPython.display import clear_output\n",
    "def process_and_combine_datasets(list_data, pipeline_path, data_path, remove_undetected=True):\n",
    "    \"\"\"\n",
    "    Processes and combines datasets from specified paths.\n",
    "\n",
    "    Parameters:\n",
    "    - list_data (list): List of dataset names.\n",
    "    - pipeline_path (str): Path to the pipeline files.\n",
    "    - data_path (str): Path to the data files.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Combined DataFrame of all processed datasets.\n",
    "    \"\"\"\n",
    "    data_all = pd.DataFrame()\n",
    "    \n",
    "    for data_name in list_data:\n",
    "        # Load dataset CSV and adjust columns\n",
    "        data_csv_path = f'{pipeline_path}/Validation/Analysis/SynRBL - {data_name}.csv'\n",
    "        data = pd.read_csv(data_csv_path).drop(['Note'], axis=1)\n",
    "        #print(data.shape)\n",
    "        data.loc[data['Result'] == 'CONSIDER', 'Result'] = False\n",
    "        data.loc[data['Result'] == 'FALSE', 'Result'] = False\n",
    "        data.loc[data['Result'] == 'TRUE', 'Result'] = True\n",
    "        #data['Result'] =\n",
    "\n",
    "        # Load and process additional data\n",
    "        merge_data_path = f'{data_path}/Validation_set/{data_name}/MCS/MCS_Impute.json.gz'\n",
    "        mcs_data_path = f'{data_path}/Validation_set/{data_name}/mcs_based_reactions.json.gz'\n",
    "        \n",
    "        merge_data = load_database(merge_data_path)\n",
    "        #print(len(merge_data))\n",
    "        merge_data = count_boundary_atoms_products_and_calculate_changes(merge_data)\n",
    "        mcs_data = load_database(mcs_data_path)\n",
    "        id = [value['R-id'] for value in merge_data]\n",
    "        mcs_data = [value for value in mcs_data if value['R-id'] in id]\n",
    "        mcs_data = calculate_chemical_properties(mcs_data)\n",
    "        #print(len(mcs_data))\n",
    "        #clear_output(wait=False)\n",
    "        \n",
    "        # Combine data\n",
    "        combined_data = pd.concat([\n",
    "            pd.DataFrame(mcs_data)[['R-id', 'reactions', 'carbon_difference', 'fragment_count', 'total_carbons', 'total_bonds', 'total_rings']],\n",
    "            data,\n",
    "            pd.DataFrame(merge_data)[['mcs_carbon_balanced', 'num_boundary', 'ring_change_merge', 'bond_change_merge']],\n",
    "        ], axis=1)\n",
    "        #print(combined_data.isnull().sum().sum())\n",
    "        combined_data.loc[(combined_data['mcs_carbon_balanced'] == False) & (combined_data['Result'] == True), 'Result']=False\n",
    "        if remove_undetected:\n",
    "            combined_data = combined_data[combined_data['mcs_carbon_balanced'] == True]\n",
    "        \n",
    "        data_all = pd.concat([data_all, combined_data], axis=0)\n",
    "    data_all = data_all.reset_index(drop=True)\n",
    "    unnamed_columns = [col for col in data_all.columns if 'Unnamed' in col]\n",
    "    data_all = data_all.drop(unnamed_columns, axis=1)\n",
    "\n",
    "    return data_all\n",
    "\n",
    "\n",
    "list_data = ['golden_dataset', 'Jaworski', 'USPTO_random_class', 'USPTO_diff', 'USPTO_unbalance_class']\n",
    "pipeline_path = '../../../Pipeline'\n",
    "data_path = '../../../Data'\n",
    "\n",
    "data_total = process_and_combine_datasets(list_data, pipeline_path, data_path, remove_undetected=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from drfp import DrfpEncoder\n",
    "rxn_smiles=data_total['reactions'].tolist()\n",
    "fps = DrfpEncoder.encode(rxn_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline as Pipelinelit\n",
    "X= fps\n",
    "y = data_total['Result']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.20      0.28        87\n",
      "           1       0.83      0.95      0.89       364\n",
      "\n",
      "    accuracy                           0.81       451\n",
      "   macro avg       0.67      0.57      0.58       451\n",
      "weighted avg       0.77      0.81      0.77       451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps = [('scaler', MinMaxScaler()), ('model', XGBClassifier(random_state=42))]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SynRBL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
